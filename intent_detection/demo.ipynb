{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glog\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/polyai-models/intent_detection'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/polyai-models/polyai-models/200909_test_huawei_wallet_30strat_min3_manyanswers.csv')\n",
    "train = pd.read_csv('/polyai-models/polyai-models/200909_train_huawei_wallet_60strat_min3_manyanswers.csv')\n",
    "val = pd.read_csv('/polyai-models/polyai-models/200909_val_huawei_wallet_10strat_min3_manyanswers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4676, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5438, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.append(val).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>intentId</th>\n",
       "      <th>labels</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6997</td>\n",
       "      <td>Why can only one city be added to the all-in-o...</td>\n",
       "      <td>Which cities can a traffic card be used in?</td>\n",
       "      <td>00154140377723915914286ed488ffbf</td>\n",
       "      <td>20</td>\n",
       "      <td>The following urban transportation cards are s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3721</td>\n",
       "      <td>Delete the bank card that is paid on the Inter...</td>\n",
       "      <td>Method of removing bank cards from online payment</td>\n",
       "      <td>00154140377750316557286ed488ffbf</td>\n",
       "      <td>102</td>\n",
       "      <td>To remove a bank card from online payment, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7352</td>\n",
       "      <td>Can an Eid be used to stay in a hotel?</td>\n",
       "      <td>Which Scenarios Can EIDs Be Used for?</td>\n",
       "      <td>00154140377719915881286ed488ffbf</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;div class=\\\"qa-answer-main\\\"&gt;eID can be used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5828</td>\n",
       "      <td>Why does the message \\\"Huawei Pay\\\" always pop...</td>\n",
       "      <td>The Huawei Pay card swiping page is displayed.</td>\n",
       "      <td>00154140377723915950286ed488ffbf</td>\n",
       "      <td>50</td>\n",
       "      <td>The reason why the Huawei Pay card swiping scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4315</td>\n",
       "      <td>Recharge process of H-coins</td>\n",
       "      <td>Use the H-coin card to recharge the account.</td>\n",
       "      <td>00154140377750316534286ed488ffbf</td>\n",
       "      <td>81</td>\n",
       "      <td>To recharge your H-coin card, do as follows: 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  \\\n",
       "0           0          6997   \n",
       "1           1          3721   \n",
       "2           2          7352   \n",
       "3           3          5828   \n",
       "4           4          4315   \n",
       "\n",
       "                                                text  \\\n",
       "0  Why can only one city be added to the all-in-o...   \n",
       "1  Delete the bank card that is paid on the Inter...   \n",
       "2             Can an Eid be used to stay in a hotel?   \n",
       "3  Why does the message \\\"Huawei Pay\\\" always pop...   \n",
       "4                        Recharge process of H-coins   \n",
       "\n",
       "                                              intent  \\\n",
       "0        Which cities can a traffic card be used in?   \n",
       "1  Method of removing bank cards from online payment   \n",
       "2              Which Scenarios Can EIDs Be Used for?   \n",
       "3     The Huawei Pay card swiping page is displayed.   \n",
       "4       Use the H-coin card to recharge the account.   \n",
       "\n",
       "                           intentId  labels  \\\n",
       "0  00154140377723915914286ed488ffbf      20   \n",
       "1  00154140377750316557286ed488ffbf     102   \n",
       "2  00154140377719915881286ed488ffbf       9   \n",
       "3  00154140377723915950286ed488ffbf      50   \n",
       "4  00154140377750316534286ed488ffbf      81   \n",
       "\n",
       "                                              answer  \n",
       "0  The following urban transportation cards are s...  \n",
       "1  To remove a bank card from online payment, per...  \n",
       "2  <div class=\\\"qa-answer-main\\\">eID can be used ...  \n",
       "3  The reason why the Huawei Pay card swiping scr...  \n",
       "4  To recharge your H-coin card, do as follows: 1...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2331, 7)\n"
     ]
    }
   ],
   "source": [
    "with tf.gfile.Open(test, \"r\") as data_file:\n",
    "    data = np.array(list(csv.reader(data_file))[1:])\n",
    "    print(data.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels= data[:,5]\n",
    "text = data[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if hparams.data_regime == \"full\":\n",
    "        train_file = \"train\"\n",
    "    elif hparams.data_regime == \"10\":\n",
    "        train_file = \"train_10\"\n",
    "    elif hparams.data_regime == \"30\":\n",
    "        train_file = \"train_30\"\n",
    "    else:\n",
    "        glog.error(f\"Invalid data regime: {hparams.data_regime}\")\n",
    "    train_data = os.path.join(\n",
    "        data_dir, hparams.task, f\"{train_file}.csv\")\n",
    "    test_data = os.path.join(data_dir, hparams.task, \"test.csv\")\n",
    "    categories_file = os.path.join(data_dir, hparams.task, \"categories.json\")\n",
    "\n",
    "    with tf.gfile.Open(categories_file, \"r\") as categories_file:\n",
    "        categories = json.load(categories_file)\n",
    "    \n",
    "    \n",
    "    labels = {}\n",
    "    encodings = {}\n",
    "\n",
    "    with tf.gfile.Open(train_data, \"r\") as data_file:\n",
    "        data = np.array(list(csv.reader(data_file))[1:])\n",
    "        labels[_TRAIN] = data[:, 1]\n",
    "        encodings[_TRAIN] = encoder_client.encode_sentences(data[:, 0])\n",
    "\n",
    "    with tf.gfile.Open(test_data, \"r\") as data_file:\n",
    "        data = np.array(list(csv.reader(data_file))[1:])\n",
    "        labels[_TEST] = data[:, 1]\n",
    "        encodings[_TEST] = encoder_client.encode_sentences(data[:, 0])\n",
    "\n",
    "    # convert labels to integers\n",
    "    labels = {\n",
    "        k: np.array(\n",
    "            [categories.index(x) for x in v]) for k, v in labels.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TRAIN = \"train\"\n",
    "_TEST = \"test\"\n",
    "\n",
    "\n",
    "def _preprocess_data(encoder_client, hparams, data_dir):\n",
    "    \"\"\"Reads the data from the files, encodes it and parses the labels\n",
    "\n",
    "    Args:\n",
    "        encoder_client: an EncoderClient\n",
    "        hparams: a tf.contrib.training.HParams object containing the model\n",
    "            and training hyperparameters\n",
    "        data_dir: The directory where the inten data has been downloaded\n",
    "\n",
    "    Returns:\n",
    "        categories, encodings, labels\n",
    "\n",
    "    \"\"\"\n",
    "    if hparams.data_regime == \"full\":\n",
    "        train_file = \"train\"\n",
    "    elif hparams.data_regime == \"10\":\n",
    "        train_file = \"train_10\"\n",
    "    elif hparams.data_regime == \"30\":\n",
    "        train_file = \"train_30\"\n",
    "    else:\n",
    "        glog.error(f\"Invalid data regime: {hparams.data_regime}\")\n",
    "    train_data = os.path.join(\n",
    "        data_dir, hparams.task, f\"{train_file}.csv\")\n",
    "    test_data = os.path.join(data_dir, hparams.task, \"test.csv\")\n",
    "    categories_file = os.path.join(data_dir, hparams.task, \"categories.json\")\n",
    "\n",
    "    with tf.gfile.Open(categories_file, \"r\") as categories_file:\n",
    "        categories = json.load(categories_file)\n",
    "\n",
    "    labels = {}\n",
    "    encodings = {}\n",
    "\n",
    "    with tf.gfile.Open(train_data, \"r\") as data_file:\n",
    "        data = np.array(list(csv.reader(data_file))[1:])\n",
    "        labels[_TRAIN] = data[:, 1]\n",
    "        encodings[_TRAIN] = encoder_client.encode_sentences(data[:, 0])\n",
    "\n",
    "    with tf.gfile.Open(test_data, \"r\") as data_file:\n",
    "        data = np.array(list(csv.reader(data_file))[1:])\n",
    "        labels[_TEST] = data[:, 1]\n",
    "        encodings[_TEST] = encoder_client.encode_sentences(data[:, 0])\n",
    "\n",
    "    # convert labels to integers\n",
    "    labels = {\n",
    "        k: np.array(\n",
    "            [categories.index(x) for x in v]) for k, v in labels.items()\n",
    "    }\n",
    "\n",
    "    return categories, encodings, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main():\n",
    "    parsed_args, hparams = parse_args_and_hparams()\n",
    "\n",
    "    if hparams.task.lower() not in [\"clinc\", \"hwu\", \"banking\"]:\n",
    "        raise ValueError(f\"{hparams.task} is not a valid task\")\n",
    "\n",
    "    encoder_client = get_encoder_client(hparams.encoder_type,\n",
    "                                        cache_dir=hparams.cache_dir)\n",
    "\n",
    "    categories, encodings, labels = _preprocess_data(\n",
    "        encoder_client, hparams, parsed_args.data_dir)\n",
    "\n",
    "    accs = []\n",
    "    eval_acc_histories = []\n",
    "    if hparams.eval_each_epoch:\n",
    "        validation_data = (encodings[_TEST], labels[_TEST])\n",
    "        verbose = 1\n",
    "    else:\n",
    "        validation_data = None\n",
    "        verbose = 0\n",
    "\n",
    "    for seed in range(hparams.seeds):\n",
    "        glog.info(f\"### Seed {seed} ###\")\n",
    "        model, eval_acc_history = train_model(\n",
    "            encodings[_TRAIN], labels[_TRAIN], categories, hparams,\n",
    "            validation_data=validation_data, verbose=verbose)\n",
    "\n",
    "        _, acc = model.evaluate(encodings[_TEST], labels[_TEST], verbose=0)\n",
    "        glog.info(f\"Seed accuracy: {acc:.3f}\")\n",
    "        accs.append(acc)\n",
    "        eval_acc_histories.append(eval_acc_history)\n",
    "\n",
    "    average_acc = np.mean(accs)\n",
    "    variance = np.std(accs)\n",
    "    glog.info(\n",
    "        f\"Average results:\\n\"\n",
    "        f\"Accuracy: {average_acc:.3f}\\n\"\n",
    "        f\"Variance: {variance:.3f}\")\n",
    "\n",
    "    results = {\n",
    "        \"Average results\": {\n",
    "            \"Accuracy\": float(average_acc),\n",
    "            \"Variance\": float(variance)\n",
    "        }\n",
    "    }\n",
    "    if hparams.eval_each_epoch:\n",
    "        results[\"Results per epoch\"] = [\n",
    "            [float(x) for x in y] for y in eval_acc_histories]\n",
    "\n",
    "    if not tf.gfile.Exists(parsed_args.output_dir):\n",
    "        tf.gfile.MakeDirs(parsed_args.output_dir)\n",
    "    with tf.gfile.Open(\n",
    "            os.path.join(parsed_args.output_dir, \"results.json\"), \"w\") as f:\n",
    "        json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_encodings, train_labels, categories, hparams,\n",
    "                validation_data=None, verbose=1):\n",
    "    \"\"\"Trains an intent classification model\n",
    "\n",
    "    Args:\n",
    "        train_encodings: np.array with the train encodings\n",
    "        train_labels: list of labels corresponding to each train example\n",
    "        categories: the set of categories\n",
    "        hparams: a tf.contrib.training.HParams object containing the model\n",
    "            and training hyperparameters\n",
    "        validation_data: (validation_encodings, validation_labels) tuple\n",
    "        verbose: the keras_model.train() verbose level\n",
    "\n",
    "    Returns:\n",
    "        model: a keras model\n",
    "        eval_acc_history: The evaluation results per epoch\n",
    "\n",
    "    \"\"\"\n",
    "    distribution = None if not hparams.balance_data else {\n",
    "        x: 1. / len(categories) for x in range(len(categories))}\n",
    "\n",
    "    batcher = SamplingBatcher(\n",
    "        train_encodings, train_labels, hparams.batch_size, distribution)\n",
    "\n",
    "    steps_per_epoch = np.ceil(len(train_labels) / hparams.batch_size)\n",
    "\n",
    "    model, eval_acc_history = _train_mlp_with_generator(\n",
    "        batcher, train_encodings.shape[1], steps_per_epoch,\n",
    "        categories, hparams, validation_data=validation_data, verbose=verbose)\n",
    "    return model, eval_acc_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import abc\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "_MAX_PER_BATCH = 3\n",
    "\n",
    "\n",
    "class SamplingBatcher(abc.Iterator):\n",
    "    \"\"\"Batcher that samples according to a given distribution.\n",
    "\n",
    "    It defaults to sampling from the data distribution.\n",
    "\n",
    "    WARNING: this class is not deterministic. if you want deterministic\n",
    "    behaviour, just freeze the numpy seed.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            examples: np.ndarray,\n",
    "            labels: np.ndarray,\n",
    "            batch_size: int,\n",
    "            sample_distribution: Optional[Dict[int, float]] = None,\n",
    "    ):\n",
    "        \"\"\"Create a new BalancedBatcher.\n",
    "\n",
    "        Args:\n",
    "            examples: np.ndarray containing examples\n",
    "            labels: np.ndarray containing labels\n",
    "            batch_size: int size of a single batch\n",
    "            sample_distribution: optional distribution over label\n",
    "                classes for sampling. This is normalized to sum to 1. Defines\n",
    "                the target distribution that batches will be sampled with.\n",
    "                Defaults to the data distribution.\n",
    "        \"\"\"\n",
    "        _validate_labels_examples(examples, labels)\n",
    "        self._examples = examples\n",
    "        self._labels = labels\n",
    "        self._label_classes = np.unique(labels)\n",
    "        self._class_to_indices = {\n",
    "            label: np.argwhere(labels == label).flatten()\n",
    "            for label in self._label_classes\n",
    "        }\n",
    "        if sample_distribution is None:\n",
    "            # Default to the data distribution\n",
    "            sample_distribution = {\n",
    "                label: float(indices.size)\n",
    "                for label, indices in self._class_to_indices.items()\n",
    "            }\n",
    "        self._label_choices, self._label_probs = (\n",
    "            self._get_label_choices_and_probs(sample_distribution))\n",
    "        self._batch_size = batch_size\n",
    "\n",
    "    def _get_label_choices_and_probs(self, sample_distribution):\n",
    "        label_choices = []\n",
    "        label_probs = []\n",
    "        weight_sum = sum(sample_distribution.values())\n",
    "        for label, weight in sample_distribution.items():\n",
    "            if label not in self._labels:\n",
    "                raise ValueError(\n",
    "                    f\"label {label} in sample distribution does not exist\")\n",
    "            if weight < 0.0:\n",
    "                raise ValueError(\n",
    "                    f\"weight {weight} for label {label} is negative\")\n",
    "            label_choices.append(label)\n",
    "            label_probs.append(weight / weight_sum)\n",
    "\n",
    "        return np.array(label_choices), np.array(label_probs)\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Generates the next batch.\n",
    "\n",
    "        Returns:\n",
    "            (batch_of_examples, batch_of_labels) - a tuple of ndarrays\n",
    "        \"\"\"\n",
    "        class_choices = np.random.choice(\n",
    "            self._label_choices, size=self._batch_size, p=self._label_probs)\n",
    "\n",
    "        batch_indices = []\n",
    "        for class_choice in class_choices:\n",
    "            indices = self._class_to_indices[class_choice]\n",
    "            batch_indices.append(np.random.choice(indices))\n",
    "\n",
    "        return self._examples[batch_indices], self._labels[batch_indices]\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Gets an iterator for this iterable\n",
    "\n",
    "        Returns:\n",
    "            self because the class is an iterator itself\n",
    "        \"\"\"\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
